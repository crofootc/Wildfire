{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project I wanted to research wildfire data and look for trends based on data provided by the US government. \n",
    "All of the information is from https://www.nifc.gov/fireInfo/fireInfo_statistics.html. \n",
    "\n",
    "In particular I am going to focus on 6 different sources of information for this project. \n",
    "    1- A Table descibing all fires greater than 100,000 acres (1997-2018) called BigFires\n",
    "    2- A table descibing the number of lightning caused fires by region\n",
    "    3- A table describing the acres of lightning caused fires by region\n",
    "    4- A table describing the number of human caused fires by region\n",
    "    5- A table describing the acres of human caused fires by region\n",
    "    6- A table describing funding towards suppression effort\n",
    "  \n",
    "  \n",
    "The first step of the project was to use python to acquire the data from the webpages and put it into a csv format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ACQUISITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigFires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is getting the BigFires information. It was stored in a webpage so I used techniques to pull the information from the html contents of the page. I am storing each scraper as a function so they can be called easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_big_fires():\n",
    "    url = 'https://www.nifc.gov/fireInfo/fireInfo_stats_lgFires.html'\n",
    "    page = requests.get(url)\n",
    "\n",
    "    # Stores the contents of the website under doc\n",
    "    doc = lh.fromstring(page.content)\n",
    "\n",
    "\n",
    "\n",
    "    # Parse data that are stored between <tr>..</tr> of HTML\n",
    "    tr_elements = doc.xpath('//tr')\n",
    "\n",
    "\n",
    "    # Quick check to ensure all rows have the same width\n",
    "    print([len(T) for T in tr_elements[:12]])\n",
    "\n",
    "    # Creates empty list\n",
    "    col = []\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    # Stores the first element (header) and an empty list for each row\n",
    "    for t in tr_elements[0]:\n",
    "        i += 1\n",
    "        name = t.text_content()\n",
    "        print(i, name)\n",
    "        col.append((name.replace(' ',''), []))\n",
    "\n",
    "\n",
    "    for j in range(1, len(tr_elements)):\n",
    "        # T is the j'th row\n",
    "        T = tr_elements[j]\n",
    "\n",
    "        # This refers back to our row width test and ensures each row should be the size of 4\n",
    "        if len(T) != 4:\n",
    "            break\n",
    "\n",
    "        # Sets i as the index of the column\n",
    "        i = 0\n",
    "        for t in T.iterchildren():\n",
    "            data = t.text_content()\n",
    "            if i > 0:\n",
    "\n",
    "                # Convert any numerical value to integers\n",
    "                try:\n",
    "                    data = int(data)\n",
    "                except:\n",
    "                    pass\n",
    "            col[i][1].append(data.title().replace(\"'\", \"\"))\n",
    "            # col[i][1].append(data.title().replace(' ',''))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    # Creates a dictionary with the data called wildfire\n",
    "    wildfire = {title: column for (title, column) in col}\n",
    "    print(wildfire)\n",
    "\n",
    "    # Converts year to integers\n",
    "    for year in range(len(wildfire['Year'])):\n",
    "        wildfire['Year'][year] = int(wildfire['Year'][year])\n",
    "\n",
    "    # Converts Total Acres to a float\n",
    "    for num in range(len(wildfire['TotalAcres'])):\n",
    "        wildfire['TotalAcres'][num] = float(wildfire['TotalAcres'][num].replace(',', ''))\n",
    "\n",
    "\n",
    "    # Creates a panda dataframe and csv from that\n",
    "    df = pd.DataFrame(wildfire)\n",
    "    print(df)\n",
    "\n",
    "    df.to_csv('big_fires.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FireCauses\n",
    "\n",
    "The next four tables were all stored on a single webpage. The basics of the code is the same with some fields customized to pull the unique information. Each of these are stored in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "# Initialize the website for the functions\n",
    "\n",
    "url = 'https://www.nifc.gov/fireInfo/fireInfo_stats_lightng-human.html'\n",
    "page = requests.get(url)\n",
    "\n",
    "# Stores the contents of the website under doc\n",
    "doc = lh.fromstring(page.content)\n",
    "\n",
    "# print(page.text)\n",
    "\n",
    "# Parse data that are stored between <tr>..</tr> of HTML\n",
    "tr_elements = doc.xpath('//tr')\n",
    "print(len(tr_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "TABLE 1 -------------------------------------\n",
    "NUMBER OF LIGHTNING FIRES (BY GEOGRAPHIC AREA)\n",
    "\n",
    "'''\n",
    "\n",
    "def get_lightning_fire_num():\n",
    "    print(\"Number Lightning Fires (by Geographic Area\")\n",
    "\n",
    "    # Quick check to ensure all rows have the same width\n",
    "    print([len(T) for T in tr_elements[:12]])\n",
    "\n",
    "    # Stores the first element (header) and an empty list for each row\n",
    "    lightning_fire_geo = []\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    for t in tr_elements[1]:\n",
    "        i += 1\n",
    "        name = t.text_content()\n",
    "        # print(i, name)\n",
    "        lightning_fire_geo.append((name.replace(' ', '').replace('*', ''), []))\n",
    "\n",
    "\n",
    "    for j in range(2, len(tr_elements)):\n",
    "        # T is the j'th row\n",
    "        T = tr_elements[j]\n",
    "\n",
    "        # This refers back to our row width test and ensures each row should be the size of 3\n",
    "        if len(T) != 13:\n",
    "            break\n",
    "\n",
    "        # Sets i as the index of the column\n",
    "        i = 0\n",
    "        for t in T.iterchildren():\n",
    "            data = t.text_content()\n",
    "            if i > 0:\n",
    "\n",
    "                # Convert any numerical value to integers\n",
    "                try:\n",
    "                    data = int(data.title().replace(\"'\", \"\"))\n",
    "                except:\n",
    "                    pass\n",
    "            lightning_fire_geo[i][1].append(data)\n",
    "            i += 1\n",
    "\n",
    "    # Creates a dictionary with the data called wildfire\n",
    "    num_lightning_fires = {title: column for (title, column) in lightning_fire_geo}\n",
    "    # print(wildfire)\n",
    "\n",
    "    # Converts all numbers to an int and any N/A to a null value\n",
    "    for key in num_lightning_fires.keys():\n",
    "        for i in range(len(num_lightning_fires[key])):\n",
    "            if num_lightning_fires[key][i] == 'N/A':\n",
    "                num_lightning_fires[key][i] = None\n",
    "            elif type(num_lightning_fires[key][i]) != type(1):\n",
    "                num_lightning_fires[key][i] = int(num_lightning_fires[key][i].replace(',', ''))\n",
    "\n",
    "    # Creates a panda dataframe and csv from that\n",
    "    df = pd.DataFrame(num_lightning_fires)\n",
    "    print(df)\n",
    "\n",
    "    df.to_csv('lightning_fire_num.csv', encoding='utf-8', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "TABLE 2 -------------------------------------\n",
    "LIGHTNING ACRES (BY GEOGRAPHIC AREA)\n",
    "\n",
    "'''\n",
    "\n",
    "def get_lightning_fire_acres():\n",
    "    print(\"Lightning Acres (by Geographic Area\")\n",
    "\n",
    "    # Quick check to ensure all rows have the same width\n",
    "    print([len(T) for T in tr_elements[:12]])\n",
    "\n",
    "    # Stores the first element (header) and an empty list for each row\n",
    "    lightning_fire_acres = []\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    for t in tr_elements[1+20]:\n",
    "        i += 1\n",
    "        name = t.text_content()\n",
    "        # print(i, name)\n",
    "        lightning_fire_acres.append((name.replace(' ','').replace('*', ''), []))\n",
    "\n",
    "\n",
    "    for j in range(2+20, len(tr_elements)):\n",
    "        # T is the j'th row\n",
    "        T = tr_elements[j]\n",
    "\n",
    "        # This refers back to our row width test and ensures each row should be the size of 3\n",
    "        if len(T) != 13:\n",
    "            break\n",
    "\n",
    "        # Sets i as the index of the column\n",
    "        i = 0\n",
    "        for t in T.iterchildren():\n",
    "            data = t.text_content()\n",
    "            if i > 0:\n",
    "\n",
    "                # Convert any numerical value to integers\n",
    "                try:\n",
    "                    data = int(data.title().replace(\"'\", \"\"))\n",
    "                except:\n",
    "                    pass\n",
    "            lightning_fire_acres[i][1].append(data)\n",
    "            i += 1\n",
    "\n",
    "    # Creates a dictionary with the data called wildfire\n",
    "    size_lightning_fires = {title: column for (title, column) in lightning_fire_acres}\n",
    "    print(size_lightning_fires)\n",
    "\n",
    "    # Converts all numbers to an int and any N/A to a null value\n",
    "    for key in size_lightning_fires.keys():\n",
    "        for i in range(len(size_lightning_fires[key])):\n",
    "            if size_lightning_fires[key][i] == 'N/A':\n",
    "                size_lightning_fires[key][i] = None\n",
    "            elif type(size_lightning_fires[key][i]) != type(1):\n",
    "                size_lightning_fires[key][i] = int(size_lightning_fires[key][i].replace(',', ''))\n",
    "\n",
    "    # Creates a panda dataframe and csv from that\n",
    "    df = pd.DataFrame(size_lightning_fires)\n",
    "    print(df)\n",
    "\n",
    "    df.to_csv('lightning_fire_acres.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Table 3 ------------------------------\n",
    "Human Caused Fires (by Geographic Area)\n",
    "\n",
    "'''\n",
    "\n",
    "def get_human_fire_num():\n",
    "    print(\"Human Caused Fires (by Geographic Area\")\n",
    "\n",
    "    # Quick check to ensure all rows have the same width\n",
    "    print([len(T) for T in tr_elements[:12]])\n",
    "\n",
    "    # Stores the first element (header) and an empty list for each row\n",
    "    human_fires_num = []\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    for t in tr_elements[1+20+20]:\n",
    "        i += 1\n",
    "        name = t.text_content()\n",
    "        # print(i, name)\n",
    "        human_fires_num.append((name.replace(' ',''), []))\n",
    "\n",
    "\n",
    "    for j in range(2+20+20, len(tr_elements)):\n",
    "        # T is the j'th row\n",
    "        T = tr_elements[j]\n",
    "\n",
    "        # This refers back to our row width test and ensures each row should be the size of 3\n",
    "        if len(T) != 13:\n",
    "            break\n",
    "\n",
    "        # Sets i as the index of the column\n",
    "        i = 0\n",
    "        for t in T.iterchildren():\n",
    "            data = t.text_content()\n",
    "            if i > 0:\n",
    "\n",
    "                # Convert any numerical value to integers\n",
    "                try:\n",
    "                    data = int(data.title().replace(\"'\", \"\"))\n",
    "                except:\n",
    "                    pass\n",
    "            human_fires_num[i][1].append(data)\n",
    "            i += 1\n",
    "\n",
    "    # Creates a dictionary with the data called wildfire\n",
    "    num_human_fires = {title: column for (title, column) in human_fires_num}\n",
    "    print(num_human_fires)\n",
    "\n",
    "    # Converts all numbers to an int and any N/A to a null value\n",
    "    for key in num_human_fires.keys():\n",
    "        for i in range(len(num_human_fires[key])):\n",
    "            if num_human_fires[key][i] == 'N/A':\n",
    "                num_human_fires[key][i] = None\n",
    "            elif type(num_human_fires[key][i]) != type(1):\n",
    "                num_human_fires[key][i] = int(num_human_fires[key][i].replace(',', ''))\n",
    "\n",
    "    # Creates a panda dataframe and csv from that\n",
    "    df = pd.DataFrame(num_human_fires)\n",
    "    print(df)\n",
    "\n",
    "    df.to_csv('human_fire_num.csv', encoding='utf-8', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Table 4 -------------------------------\n",
    "Human Caused Acres (by Geographic Area)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def get_human_fire_acres():\n",
    "    print(\"Human Caused Acres (by Geographic Area\")\n",
    "\n",
    "    # Quick check to ensure all rows have the same width\n",
    "    print([len(T) for T in tr_elements[:12]])\n",
    "\n",
    "    # Stores the first element (header) and an empty list for each row\n",
    "    human_fires_acres = []\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    for t in tr_elements[1+20+20+20]:\n",
    "        i += 1\n",
    "        name = t.text_content()\n",
    "        # print(i, name)\n",
    "        human_fires_acres.append((name.replace(' ',''), []))\n",
    "\n",
    "\n",
    "    for j in range(2+20+20+20, len(tr_elements)):\n",
    "        # T is the j'th row\n",
    "        T = tr_elements[j]\n",
    "\n",
    "        # This refers back to our row width test and ensures each row should be the size of 3\n",
    "        if len(T) != 13:\n",
    "            break\n",
    "\n",
    "        # Sets i as the index of the column\n",
    "        i = 0\n",
    "        for t in T.iterchildren():\n",
    "            data = t.text_content()\n",
    "            if i > 0:\n",
    "\n",
    "                # Convert any numerical value to integers\n",
    "                try:\n",
    "                    data = int(data.title().replace(\"'\", \"\"))\n",
    "                except:\n",
    "                    pass\n",
    "            human_fires_acres[i][1].append(data)\n",
    "            i += 1\n",
    "\n",
    "    # Creates a dictionary with the data called wildfire\n",
    "    size_human_fires = {title: column for (title, column) in human_fires_acres}\n",
    "    print(size_human_fires)\n",
    "\n",
    "    # Converts all numbers to an int and any N/A to a null value\n",
    "    for key in size_human_fires.keys():\n",
    "        for i in range(len(size_human_fires[key])):\n",
    "            if size_human_fires[key][i] == 'N/A':\n",
    "                size_human_fires[key][i] = None\n",
    "            elif type(size_human_fires[key][i]) != type(1):\n",
    "                size_human_fires[key][i] = int(size_human_fires[key][i].replace(',', ''))\n",
    "\n",
    "    # Creates a panda dataframe and csv from that\n",
    "    df = pd.DataFrame(size_human_fires)\n",
    "    print(df)\n",
    "\n",
    "    df.to_csv('human_fire_acres.csv', encoding='utf-8', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Fires\n",
    "\n",
    "The next table is the table of total fires by region. It follows the same process as the functions listed above. Note: due to inaccuacies prior to 1983 all data from before then is not added to the table. Additional cleansing is performed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_fires():\n",
    "    url = 'https://www.nifc.gov/fireInfo/fireInfo_stats_totalFires.html'\n",
    "    page = requests.get(url)\n",
    "\n",
    "    # Stores the contents of the website under doc\n",
    "    doc = lh.fromstring(page.content)\n",
    "\n",
    "    # print(page.text)\n",
    "\n",
    "    # Parse data that are stored between <tr>..</tr> of HTML\n",
    "    tr_elements = doc.xpath('//tr')\n",
    "    print(tr_elements)\n",
    "\n",
    "    # Quick check to ensure all rows have the same width\n",
    "    print([len(T) for T in tr_elements[:12]])\n",
    "\n",
    "    # Creates empty list\n",
    "    col = []\n",
    "    i = 0\n",
    "\n",
    "    # Stores the first element (header) and an empty list for each row\n",
    "    for t in tr_elements[2]:\n",
    "        i += 1\n",
    "        name = t.text_content()\n",
    "        print(i, name)\n",
    "        col.append((name.replace(' ',''), []))\n",
    "\n",
    "\n",
    "    for j in range(3, len(tr_elements)):\n",
    "        # T is the j'th row\n",
    "        T = tr_elements[j]\n",
    "\n",
    "        # This refers back to our row width test and ensures each row should be the size of 3\n",
    "        if len(T) != 3:\n",
    "            break\n",
    "\n",
    "        # Sets i as the index of the column\n",
    "        i = 0\n",
    "        for t in T.iterchildren():\n",
    "            data = t.text_content()\n",
    "            if i > 0:\n",
    "\n",
    "                # Convert any numerical value to integers\n",
    "                try:\n",
    "                    data = int(data)\n",
    "                except:\n",
    "                    pass\n",
    "            col[i][1].append(data.title().replace(\"'\", \"\"))\n",
    "            i += 1\n",
    "\n",
    "    # Creates a dictionary with the data called wildfire\n",
    "    wildfire = {title: column for (title, column) in col}\n",
    "    print(wildfire)\n",
    "\n",
    "    # Converts year to integers and removes data with years prior to 1983\n",
    "    for year in range(len(wildfire['Year'])):\n",
    "        wildfire['Year'][year] = int(wildfire['Year'][year])\n",
    "\n",
    "    year = 0\n",
    "    while year < len(wildfire['Year']):\n",
    "        if wildfire['Year'][year] < 1983:\n",
    "            del wildfire['Year'][year]\n",
    "            del wildfire['Fires'][year]\n",
    "            del wildfire['Acres'][year]\n",
    "        elif wildfire['Year'][year] == 1926:\n",
    "            del wildfire['Year'][year]\n",
    "            del wildfire['Fires'][year]\n",
    "            del wildfire['Acres'][year]\n",
    "            break\n",
    "        else:\n",
    "            year += 1\n",
    "\n",
    "    # Converts Fires to a float\n",
    "    for num in range(len(wildfire['Fires'])):\n",
    "        wildfire['Fires'][num] = float(wildfire['Fires'][num].replace(',', '').replace('*', ''))\n",
    "\n",
    "    # Converts Acres to a float\n",
    "    for num in range(len(wildfire['Acres'])):\n",
    "        wildfire['Acres'][num] = float(wildfire['Acres'][num].replace(',', '').replace('*', ''))\n",
    "\n",
    "\n",
    "    # Creates a panda dataframe and csv from that\n",
    "    df = pd.DataFrame(wildfire)\n",
    "    print(df)\n",
    "\n",
    "    df.to_csv('total_fires.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression Costs\n",
    "This table contains information on the money that various agencies have put towards suppression costs. The information for this table was stored on a pdf document so the process is different to acquire the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPDF2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6b998006c0dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suppression_costs():\n",
    "    # Extracts the pdf information as a string object\n",
    "    pdfFileObj = open('SuppCosts.pdf', 'rb')\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    # print(pdfReader.numPages)\n",
    "    pageObj = pdfReader.getPage(0)\n",
    "    pdfString = pageObj.extractText()\n",
    "    # print(pdfString)\n",
    "    pdfFileObj.close()\n",
    "\n",
    "    # Test to make sure is a string\n",
    "    # print(type(pdfString))\n",
    "\n",
    "    # Changing the string object into a more manageable format\n",
    "    data = pdfString.splitlines()\n",
    "    title = data.pop(0)\n",
    "    print(title, \"\\n\")\n",
    "\n",
    "    # Setting up the headers\n",
    "    col_headers = []\n",
    "    for i in range(6):\n",
    "        col_headers.append(data.pop(0).replace(' ', ''))\n",
    "    # print(col_headers)\n",
    "\n",
    "    # Setting up the data for each column into their own list\n",
    "    data_raw = data[0].split()\n",
    "    # print(data_raw)\n",
    "    for i in range(15):\n",
    "        del data_raw[-1]\n",
    "    # print(\"raw:\", data_raw)\n",
    "    years = []\n",
    "    fires = []\n",
    "    acres = []\n",
    "    forestService = []\n",
    "    doiAgencies = []\n",
    "    total = []\n",
    "\n",
    "    # Add data to each list\n",
    "    for i in range(len(data_raw)):\n",
    "        if i % 6 == 0:\n",
    "            years.append(int((data_raw.pop(0)).title().replace(\"'\", \"\")))\n",
    "        if i % 6 == 1:\n",
    "            fires.append(int((data_raw.pop(0)).replace(',', '').strip()))\n",
    "        if i % 6 == 2:\n",
    "            acres.append(float((data_raw.pop(0)).replace(',', '').replace('$', '').title().replace(\"'\", \"\")))\n",
    "        if i % 6 == 3:\n",
    "            forestService.append(float((data_raw.pop(0)).replace(',', '').replace('$',' ').title().replace(\"'\", \"\")))\n",
    "        if i % 6 == 4:\n",
    "            doiAgencies.append(float((data_raw.pop(0)).replace(',', '').replace('$', '').title().replace(\"'\", \"\")))\n",
    "        if i % 6 == 5:\n",
    "            total.append(float((data_raw.pop(0)).replace(',', '').replace('$', '').title().replace(\"'\", \"\")))\n",
    "\n",
    "    # print(years, total)\n",
    "\n",
    "    # Combining everything into a dictionary\n",
    "    suppression = dict()\n",
    "    suppression[col_headers[0]] = years\n",
    "    suppression[col_headers[1]] = fires\n",
    "    suppression[col_headers[2]] = acres\n",
    "    suppression[col_headers[3]] = forestService\n",
    "    suppression[col_headers[4]] = doiAgencies\n",
    "    suppression[col_headers[5]] = total\n",
    "\n",
    "    # print(suppression)\n",
    "\n",
    "    # Creates a panda dataframe and csv from that\n",
    "    df = pd.DataFrame(suppression)\n",
    "    print(df)\n",
    "    df.to_csv('suppression_costs.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Information\n",
    "\n",
    "Now that the functions have all been written following can be ran to create the csv file for each webscraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "1 Year\n",
      "2 Fire Name\n",
      "3 State\n",
      "4 Total Acres\n",
      "{'Year': ['2004', '2006', '2017', '2007', '2009', '2004', '1997', '2012', '2004', '2011', '2004', '2009', '2005', '2002', '2015', '2002', '2002', '2012', '2018', '2004', '2009', '2018', '2015', '2006', '2014', '2007', '2016', '2007', '1999', '2002', '2009', '2012', '2017', '2012', '2011', '2011', '2010', '2007', '2007', '2012', '1999', '2000', '2018', '2004', '2015', '2004', '2003', '2015', '2017', '2017', '2004', '2002', '2013', '2014', '2006', '2012', '2005', '2007', '2006', '2018', '2018', '2002', '2006', '2011', '2006', '2008', '2017', '2015', '2000', '2003', '2012', '1999', '2013', '2015', '2007', '2004', '2002', '2014', '2005', '2000', '2008', '2000', '2017', '2006', '2016', '2000', '2012', '2007', '2001', '2016', '2004', '2018', '2011', '2010', '2012', '1999', '2005', '2009', '2005', '2000', '2009', '2009', '2007', '2008', '2006', '2005', '2011', '2012', '2007', '2009', '2017', '2007', '2017', '2011', '2015', '2013', '2011', '2018', '2017', '2015', '2000', '2002', '2006', '2013', '2012', '2005', '2015', '1999', '2015', '2012', '1999', '2007', '2013', '2002', '2000', '2007', '2017', '2014', '2018', '2016', '2013', '2012', '2003', '2006', '2015', '2017', '2011', '2009', '1999', '2009', '2000', '2006', '2002', '2000', '2007', '2011', '2016', '2004', '2006', '2002', '2004', '2006', '2006', '2005', '2016', '2006', '2013', '2015', '2011', '2017', '2015', '2000', '2013', '2010', '2006', '2007', '2006', '2003', '2011', '2018', '2000', '2012', '2005', '2001', '2008', '2011', '2015', '2008', '2018', '2015', '2007', '2011', '2009', '2006', '2018', '1999', '2000', '2002'], 'FireName': ['Taylor Complex', 'East Amarillo Complex', 'Nw Oklahoma Complex', 'Murphy Complex', 'Railbelt Complex', 'Eagle Complex', 'Inowak', 'Long Draw', 'Solstice Complex', 'Wallow', 'Boundary Fire', 'Minto Flats South', 'Southern Nevada    Complex', 'Biscuit (Formerly    Florence)', 'Tanana Area Fires', 'Trimbly Creek', 'Rodeo/Chediski    Complex', 'Holloway', 'Mendocino Complex', 'Central Complex', 'Crazy Mountain    Complex', 'Martin', 'Ruby Area Fires', 'Eastern Oklahoma Ia', 'Buzzard Complex', 'Big Turnaround    Complex', 'Anderson Creek', 'Milford Flat', 'Dun Glen Complex', 'Kraft Complex', 'Little Black One\\xa0', 'Mustang Complex', 'Perryton', 'Rush', 'Rock House', 'Honey Prairie', 'Long Butte', 'Cascade Complex', 'East Zone Complex', 'Whitewater- Baldy', 'Sadler Complex', 'Valley Complex', 'Rhea', 'Pingo', 'Soda', 'Winter Trail', 'Cedar', 'Sushgitit Hills', 'Thomas', 'Lodgepole Complex', 'Chicken Complex', 'Geskamina Lake', 'Rim', 'Calton Complex', 'North Central Texas    Ia', 'Ash Creek', 'Cave Creek Complex', 'Zaca Two', 'Winters', 'South Sugarloaf', 'Carr', 'Reindeer', 'Derby Fire', 'Horseshoe 2', 'Crystal', 'Glass Fire', 'Roosters Comb', 'North Star', 'Clear Creek Complex', 'Needles', 'Kinyon Road', 'Battle Mountain    Complex', 'Lime Hills', 'Holtnakatna', 'Witch', 'Wolf Creek', 'Minchumina Group', 'Funny River', 'Clover', 'Eastern Idaho Complex', 'Klamath Theater', 'Command 24', 'Chetco Bar', 'Charleston Complex', 'Pioneer', 'Scf Wilderness', 'Halstead', 'Rowland', 'Lakeview Complex', 'Range 12', 'Camp Creek', 'Klondike', 'Deaton Cole', 'Toklat', 'Rosebud Creek Complex', 'Corridor Complex', 'Delamar', 'Big Creek', 'Beaver Creek', 'Zitziana', 'Titna River', 'Tonclonukna Creek', 'Winecup Complex', 'Basin Complex', 'Day', 'Chapman Creek', 'Cooper Mountain Ranch', 'Miller Homestead', 'Bugaboo Scrub Fire', 'Station', 'Rice Ridge', 'Elk Mountain', 'Four Seasons Complex', 'Wildcat', 'Aniak Complex', 'Moore Creek', 'Las Conchas', 'Camp', 'West Mims', 'Rough', 'Two Fork', 'Mcnally', 'Sheep', 'Pony Complex', 'Trinity Ridge', 'Meadow Valley', 'Okanogan Complex', 'Mule Butte', 'Rock', 'Flattop 2', 'Big Bar Complex', 'Egley Complex', 'Silver', 'Hayman', 'KateS Basin Complex', 'Antelope Complex', 'Lefors East', 'Happy Camp Complex', 'Goose Creek', 'Soberanes', 'Elk Complex', 'Chalky', 'Missouri    Breaks Complex', 'Parks Hwy', 'Isahultila', 'Diamond Creek', 'Pk Complex', 'Nowitna', 'Jungo    Complex', 'Wood River 1', 'Diamond    Peak', 'Black Pulaski Complex', 'Blackjack    Bay Complex', 'Bering    Creek', 'Shower Bath Complex', 'Swenson', 'Hot Pot', 'Evansville', 'Pine Ridge Complex', 'Tool    Box Complex', 'Willow', 'Oklahoma Fire    Response', 'South End Complex', 'Boundary Creek', 'Alatna Complex', 'Tripod Complex', 'Beaver Creek', 'Sea', 'Indian Creek', 'Central Lnu Complex', 'Canyon Creek Complex', 'Mule    Dry', 'West Fork Complex', 'Jefferson', 'Columbia Complex', 'Florida Bugaboo', 'Amazon', 'Simi    Incident', 'High Cascades', 'Spring Creek', 'Jackson    Fire', 'Clay    Springs', 'Sheenjek River', 'Survey Line', 'Iron    & Alps Complexes', 'Southeast Texas    Complex', 'Big Mud River 1', 'Dunn    Mtn. Assist', 'Pole Creek', 'Cornet-Windy Ridge', 'Rattlesnake', 'Donaldson', 'Rex Creek ', 'Bar Complex', 'Boxcar', 'Kink', 'Maudlow/    Toston', 'Vinasale'], 'State': ['Ak', 'Tx', 'Ok', 'Id', 'Ak', 'Ak', 'Ak', 'Or', 'Ak', 'Az', 'Ak', 'Ak', 'Nv', 'Or', 'Ak', 'Or', 'Az', 'Nv', 'Ca', 'Ak', 'Ak', 'Ca', 'Ak', 'Ok', 'Or', 'Ga', 'Ok', 'Ut', 'Nv', 'Sd', 'Ak', 'Id', 'Tx', 'Ca', 'Tx', 'Ga', 'Id', 'Id', 'Id', 'Nm', 'Nv', 'Mt', 'Ok', 'Ak', 'Id', 'Ak', 'Ca', 'Ak', 'Ca', 'Mt', 'Ak', 'A', 'Ca', 'Wa', 'Tx', 'Mt', 'Az', 'Ca', 'Nv', 'Nv', 'Ca', 'Ca', 'Mt', 'Az', 'Id', 'Tx', 'Nv', 'Wa', 'Id', 'Wa', 'Id', 'Nv', 'Ak', 'Ak', 'Ca', 'Ak', 'Ak', 'Ak', 'Id', 'Id', 'Ca', 'Wa', 'Or', 'Nv', 'Id', 'Id', 'Id', 'Id', 'Or', 'Wa', 'Ak', 'Or', 'Tx', 'Ak', 'Mt', 'Nv', 'Nv', 'Ak', 'Ak', 'Ak', 'Ak', 'Ak', 'Nv', 'Ca', 'Ca', 'Ak', 'Tx', 'Or', 'Ga', 'Ca', 'Mt', 'Id', 'Nv', 'Tx', 'Ak', 'Ak', 'Nm', 'Ca', 'Ga', 'Ca', 'Wa', 'Ca', 'Nv', 'Id', 'Id', 'Nv', 'Wa', 'Id', 'Ak', 'Id', 'Ca', 'Or', 'Nm', 'Co', 'Wy', 'Nv', 'Tx', 'Ca', 'Nv', 'Ca', 'Id', 'Mt', 'Mt', 'Ak', 'Ak', 'Wa', 'Tx', 'Ak', 'Nv', 'Ak', 'Id', 'Mt', 'Ga', 'Ak', 'Id', 'Tx', 'Nv', 'Ak', 'Mt', 'Or', 'Az', 'Ok', 'Or', 'Ak', 'Ak', 'Wa', 'Id', 'Ak', 'Nv', 'Ca', 'Or', 'Wa', 'Ak', 'Id', 'Or', 'Fl', 'Nv', 'Ca', 'Or', 'Co', 'Or', 'Ut', 'Ak', 'Ak', 'Ca', 'Tx', 'Ak', 'Mt', 'Ut', 'Or', 'Id', 'Nm', 'Ak', 'Ca', 'Or', 'Ak', 'Mt', 'Ak'], 'TotalAcres': ['1,305,592', '907,245', '779,292', '652,016', '636,224', '614,974', '610,000', '557,628', '547,505', '538,049', '537,098', '517,078', '508,751', '500,068', '498,043', '480,000', '468,638', '460,850', '459,123', '451,162', '447,420', '435,569', '421,613', '413,964', '395,747', '386,722', '367,740', '363,052', '361,658', '351,000', '349,450', '341,448', '318,156', '315,577', '314,444', '309,200', '306,113', '302,376', '300,022', '297,845', '297,000', '292,070', '286,196', '285,885', '283,180', '279,865', '273,246', '270,747', '270,000', '270,000', '257,720', '257,549', '257,314', '256,108', '250,942', '249,562', '248,310', '240,207', '238,458', '233,458', '229,651', '227,800', '223,570', '222,954', '220,042', '219,556', '218,380', '218,138', '216,961', '213,000', '210,874', '208,031', '201,808', '198,133', '197,990', '197,067', '196,584', '195,858', '192,846', '192,450', '192,038', '192,000', '191,125', '190,421', '188,404', '182,600', '181.948', '180,000', '179,400', '176,600', '175,815', '175,258', '175,000', '171,727', '171,444', '171,600', '170,089', '169,639', '167,766', '166,177', '164,542', '164,318', '163,767', '162,818', '162,702', '162,670', '162,625', '160,853', '160,727', '160,577', '160,187', '160,000', '159,986', '159,308', '157,783', '157,747', '156,593', '153,336', '152,515', '151,623', '151,000', '150,696', '150,270', '149,384', '146,832', '146,035', '145,282', '144,000', '142,637', '140,954', '140,948', '140,359', '138,546', '137,760', '137,600', '136,778', '135,000', '134,056', '132.200', '132,127', '131,258', '131,000', '130,927', '130,186', '128,617', '128,272', '126,734', '126,582', '125,480', '125,382', '125,000', '124,905', '124,492', '122,994', '122,600', '122,500', '122,292', '122,000', '121,210', '120,085', '119,500', '117,686', '117,553', '113,463', '113,157', '113,011', '111,490', '111,193', '110,827', '110,720', '110,261', '110,000', '109,615', '109,436', '109,259', '108,574', '108,564', '108,304', '108,154', '108,045', '108,000', '107,846', '107,240', '106,800', '105,805', '104,818', '103,170', '102,383', '102,191', '102,089', '102,000', '101,563', '101,150', '100,414', '100,207', '100,000', '100,000', '100,000']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year                        FireName State  TotalAcres\n",
      "0    2004                  Taylor Complex    Ak   1305592.0\n",
      "1    2006           East Amarillo Complex    Tx    907245.0\n",
      "2    2017             Nw Oklahoma Complex    Ok    779292.0\n",
      "3    2007                  Murphy Complex    Id    652016.0\n",
      "4    2009                Railbelt Complex    Ak    636224.0\n",
      "5    2004                   Eagle Complex    Ak    614974.0\n",
      "6    1997                          Inowak    Ak    610000.0\n",
      "7    2012                       Long Draw    Or    557628.0\n",
      "8    2004                Solstice Complex    Ak    547505.0\n",
      "9    2011                          Wallow    Az    538049.0\n",
      "10   2004                   Boundary Fire    Ak    537098.0\n",
      "11   2009               Minto Flats South    Ak    517078.0\n",
      "12   2005      Southern Nevada    Complex    Nv    508751.0\n",
      "13   2002  Biscuit (Formerly    Florence)    Or    500068.0\n",
      "14   2015               Tanana Area Fires    Ak    498043.0\n",
      "15   2002                   Trimbly Creek    Or    480000.0\n",
      "16   2002       Rodeo/Chediski    Complex    Az    468638.0\n",
      "17   2012                        Holloway    Nv    460850.0\n",
      "18   2018               Mendocino Complex    Ca    459123.0\n",
      "19   2004                 Central Complex    Ak    451162.0\n",
      "20   2009       Crazy Mountain    Complex    Ak    447420.0\n",
      "21   2018                          Martin    Ca    435569.0\n",
      "22   2015                 Ruby Area Fires    Ak    421613.0\n",
      "23   2006             Eastern Oklahoma Ia    Ok    413964.0\n",
      "24   2014                 Buzzard Complex    Or    395747.0\n",
      "25   2007       Big Turnaround    Complex    Ga    386722.0\n",
      "26   2016                  Anderson Creek    Ok    367740.0\n",
      "27   2007                    Milford Flat    Ut    363052.0\n",
      "28   1999                Dun Glen Complex    Nv    361658.0\n",
      "29   2002                   Kraft Complex    Sd    351000.0\n",
      "..    ...                             ...   ...         ...\n",
      "168  2011                    Indian Creek    Nv    110827.0\n",
      "169  2017             Central Lnu Complex    Ca    110720.0\n",
      "170  2015            Canyon Creek Complex    Or    110261.0\n",
      "171  2000                     Mule    Dry    Wa    110000.0\n",
      "172  2013               West Fork Complex    Ak    109615.0\n",
      "173  2010                       Jefferson    Id    109436.0\n",
      "174  2006                Columbia Complex    Or    109259.0\n",
      "175  2007                 Florida Bugaboo    Fl    108574.0\n",
      "176  2006                          Amazon    Nv    108564.0\n",
      "177  2003                Simi    Incident    Ca    108304.0\n",
      "178  2011                   High Cascades    Or    108154.0\n",
      "179  2018                    Spring Creek    Co    108045.0\n",
      "180  2000                 Jackson    Fire    Or    108000.0\n",
      "181  2012                 Clay    Springs    Ut    107846.0\n",
      "182  2005                  Sheenjek River    Ak    107240.0\n",
      "183  2001                     Survey Line    Ak    106800.0\n",
      "184  2008        Iron    & Alps Complexes    Ca    105805.0\n",
      "185  2011      Southeast Texas    Complex    Tx    104818.0\n",
      "186  2015                 Big Mud River 1    Ak    103170.0\n",
      "187  2008             Dunn    Mtn. Assist    Mt    102383.0\n",
      "188  2018                      Pole Creek    Ut    102191.0\n",
      "189  2015              Cornet-Windy Ridge    Or    102089.0\n",
      "190  2007                     Rattlesnake    Id    102000.0\n",
      "191  2011                       Donaldson    Nm    101563.0\n",
      "192  2009                      Rex Creek     Ak    101150.0\n",
      "193  2006                     Bar Complex    Ca    100414.0\n",
      "194  2018                          Boxcar    Or    100207.0\n",
      "195  1999                            Kink    Ak    100000.0\n",
      "196  2000              Maudlow/    Toston    Mt    100000.0\n",
      "197  2002                        Vinasale    Ak    100000.0\n",
      "\n",
      "[198 rows x 4 columns]\n",
      "Human Caused Acres (by Geographic Area\n",
      "[1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "{'Year': ['2018', '2017', '2016', '2015', '2014', '2013', '2012', '2011', '2010', '2009', '2008', '2007', '2006', '2005', '2004', '2003', '2002', '2001'], 'Alaska': ['28,946', '6,890', '10,069', '26,652', '222,909', '161,767', '33,840', '25,236', '106,759', '43,887', '1,857', '59,007', '147,292', '8,184', '17,789', '22,093', '427,321', '206,844'], 'Northwest': ['609,578', '465,864', '436,106', '702,206', '147,583', '115,842', '127,303', '30,038', '70,684', '29,592', '99,706', '244,335', '112,098', '219,012', '58,178', '126,381', '105,544', '98,677'], 'NorthernCalifornia': ['1,404,463', '343,195', '93,699', '308,762', '181,965', '151,677', '178,818', '20,051', '22,701', '57,997', '91,022', '153,154', '146,999', '37,658', '146,720', '96,415', '39,560', '101,240'], 'SouthernCalifornia': ['324,102', '532,640', '464,718', '96,990', '74,082', '380,390', '80,539', '80,427', '67,236', '296,429', '454,249', '855,978', '342,864', '61,728', '84,075', '653,016', '412,447', '101,240'], 'NorthernRockies': ['48,372', '135,131', '84,249', '77,905', '29,088', '40,184', '279,369', '18,219', '25,574', '32,651', '105,634', '237,835', '126,078', '53,616', '23,585', '137,309', '65,891', '29,981'], 'GreatBasin': ['1,030,761', '788,769', '333,318', '49,066', '43,363', '30,049', '483,019', '64,280', '183,684', '16,975', '120,391', '288,627', '278,288', '187,248', '13,636', '182,916', '101,986', '114,996'], 'WesternGreatBasin': ['N/A', 'N/A', 'N/A', 'N/A', '12,145', '10,459', '92,671', '54,016', '3,173', '26,046', '17,769', '46,057', '46,947', '43,811', '13,864', '5,161', '29,288', '57,636'], 'Southwest': ['309,546', '207,818', '219,103', '19,596', '74,219', '99,900', '106,421', '1,810,445', '69,860', '210,642', '339,201', '90,660', '392,892', '267,043', '63,062', '127,332', '772,299', '20,229'], 'RockyMountains': ['504,416', '645,162', '530,831', '163,871', '71,823', '35,258', '393,477', '300,776', '118,702', '76,842', '117,554', '85,442', '209,693', '48,356', '35,346', '87,823', '661,679', '75,483'], 'EasternArea': [374, '41,459', '97,094', '100,094', '53,855', '64,635', '119,274', '117,521', '128,649', '118,230', '69,396', '230,750', '115,171', '85,589', '101,089', '235,391', '104,900', '196,226'], 'SouthernArea': ['1,329,945', '1,663,548', '1,497,423', '467,319', '74,082', '171,819', '605,518', '2,835,762', '506,337', '1,163,455', '2,013,212', '1,157,515', '2,486,522', '509,082', '407,456', '248,412', '356,204', '761,605'], 'Total': ['5,640,489', '4,830,476', '3,766,610', '2,012,461', '1,582,770', '1,261,980', '2,500,249', '5,356,771', '1,303,449', '2,072,746', '3,429,991', '3,449,360', '4,404,844', '1,521,327', '964,800', '1,922,249', '3,077,119', '1,748,661']}\n",
      "    Year  Alaska  Northwest  NorthernCalifornia  SouthernCalifornia  \\\n",
      "0   2018   28946     609578             1404463              324102   \n",
      "1   2017    6890     465864              343195              532640   \n",
      "2   2016   10069     436106               93699              464718   \n",
      "3   2015   26652     702206              308762               96990   \n",
      "4   2014  222909     147583              181965               74082   \n",
      "5   2013  161767     115842              151677              380390   \n",
      "6   2012   33840     127303              178818               80539   \n",
      "7   2011   25236      30038               20051               80427   \n",
      "8   2010  106759      70684               22701               67236   \n",
      "9   2009   43887      29592               57997              296429   \n",
      "10  2008    1857      99706               91022              454249   \n",
      "11  2007   59007     244335              153154              855978   \n",
      "12  2006  147292     112098              146999              342864   \n",
      "13  2005    8184     219012               37658               61728   \n",
      "14  2004   17789      58178              146720               84075   \n",
      "15  2003   22093     126381               96415              653016   \n",
      "16  2002  427321     105544               39560              412447   \n",
      "17  2001  206844      98677              101240              101240   \n",
      "\n",
      "    NorthernRockies  GreatBasin  WesternGreatBasin  Southwest  RockyMountains  \\\n",
      "0             48372     1030761                NaN     309546          504416   \n",
      "1            135131      788769                NaN     207818          645162   \n",
      "2             84249      333318                NaN     219103          530831   \n",
      "3             77905       49066                NaN      19596          163871   \n",
      "4             29088       43363            12145.0      74219           71823   \n",
      "5             40184       30049            10459.0      99900           35258   \n",
      "6            279369      483019            92671.0     106421          393477   \n",
      "7             18219       64280            54016.0    1810445          300776   \n",
      "8             25574      183684             3173.0      69860          118702   \n",
      "9             32651       16975            26046.0     210642           76842   \n",
      "10           105634      120391            17769.0     339201          117554   \n",
      "11           237835      288627            46057.0      90660           85442   \n",
      "12           126078      278288            46947.0     392892          209693   \n",
      "13            53616      187248            43811.0     267043           48356   \n",
      "14            23585       13636            13864.0      63062           35346   \n",
      "15           137309      182916             5161.0     127332           87823   \n",
      "16            65891      101986            29288.0     772299          661679   \n",
      "17            29981      114996            57636.0      20229           75483   \n",
      "\n",
      "    EasternArea  SouthernArea    Total  \n",
      "0           374       1329945  5640489  \n",
      "1         41459       1663548  4830476  \n",
      "2         97094       1497423  3766610  \n",
      "3        100094        467319  2012461  \n",
      "4         53855         74082  1582770  \n",
      "5         64635        171819  1261980  \n",
      "6        119274        605518  2500249  \n",
      "7        117521       2835762  5356771  \n",
      "8        128649        506337  1303449  \n",
      "9        118230       1163455  2072746  \n",
      "10        69396       2013212  3429991  \n",
      "11       230750       1157515  3449360  \n",
      "12       115171       2486522  4404844  \n",
      "13        85589        509082  1521327  \n",
      "14       101089        407456   964800  \n",
      "15       235391        248412  1922249  \n",
      "16       104900        356204  3077119  \n",
      "17       196226        761605  1748661  \n",
      "Human Caused Fires (by Geographic Area\n",
      "[1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "{'Year': ['2018', '2017', '2016', '2015', '2014', '2013', '2012', '2011', '2010', '2009', '2008', '2007', '2006', '2005', '2004', '2003', '2002', '2001'], 'Alaska': [229, 209, 343, 351, 329, 391, 275, 377, 359, 328, 265, 247, 254, 296, 426, 379, 378, 320], 'Northwest': ['2,787', '2,150', '2,082', '2,898', '2,155', '2,107', '1,449', '1,342', '1,078', '1,624', '1,365', '2,346', '2,666', '1,924', '1,901', '2,370', '2,148', '2,160'], 'NorthernCalifornia': ['3,428', '3,445', '3,266', '3,802', '3,605', '4,703', '3,356', '2,791', '2,502', '3,677', '3,407', '3,093', '3,676', '3,010', '3,613', '3,795', '3,789', '1,060'], 'SouthernCalifornia': ['4,322', '5,201', '3,900', '3,778', '3,527', '4,334', '4,146', '4,633', '3,394', '4,412', '5,208', '5,140', '3,166', '3,781', '3,845', '3,929', '4,060', '4,099'], 'NorthernRockies': ['2,137', '2,646', '1,784', '2,246', '1,646', '1,468', '2,105', '1,109', '1,107', '1,344', '1,971', '2,005', '2,303', '1,183', '1,883', '1,970', '1,665', '1,801'], 'GreatBasin': ['1,631', '1,988', '1,251', 985, 782, 773, '1,140', 712, 810, 726, 826, '1,048', 943, 813, 526, 944, 730, '2,160'], 'WesternGreatBasin': ['N/A', 'N/A', 'N/A', 'N/A', 247, 215, 367, 383, 212, 209, 224, 425, 331, 262, 173, 227, 215, 277], 'Southwest': ['2,072', '2,172', '2,084', '1,327', '1,380', '1,519', '1,410', '2,104', '1,600', '2,074', '2,013', '1,730', '2,511', '3,287', '1,491', '1,657', '2,668', '2,096'], 'RockyMountains': ['1,394', '2,150', '2,048', '1,909', '1,667', '1,455', '3,592', '2,105', '1,962', '1,434', '1,616', '1,876', '2,968', '1,940', 704, '4,214', '2,118', '4,135'], 'EasternArea': ['6,822', '9,757', '11,163', '11,553', '6,996', '7,056', '10,942', '8,992', '15,675', '15,719', '11,152', '12,453', '14,227', '13,014', '11,781', '14,851', '12,857', '18,743'], 'SouthernArea': ['26,754', '33,828', '33,011', '30,067', '33,345', '14,328', '29,549', '39,329', '36,108', '38,103', '42,043', '43,083', '47,175', '28,920', '27,758', '16,479', '31,394', '34,605'], 'Total': ['51,576', '63,546', '60,932', '58,916', '55,679', '38,349', '58,331', '63,877', '64,807', '69,650', '70,093', '73,446', '80,220', '58,430', '54,101', '50,815', '62,022', '70,066']}\n",
      "    Year  Alaska  Northwest  NorthernCalifornia  SouthernCalifornia  \\\n",
      "0   2018     229       2787                3428                4322   \n",
      "1   2017     209       2150                3445                5201   \n",
      "2   2016     343       2082                3266                3900   \n",
      "3   2015     351       2898                3802                3778   \n",
      "4   2014     329       2155                3605                3527   \n",
      "5   2013     391       2107                4703                4334   \n",
      "6   2012     275       1449                3356                4146   \n",
      "7   2011     377       1342                2791                4633   \n",
      "8   2010     359       1078                2502                3394   \n",
      "9   2009     328       1624                3677                4412   \n",
      "10  2008     265       1365                3407                5208   \n",
      "11  2007     247       2346                3093                5140   \n",
      "12  2006     254       2666                3676                3166   \n",
      "13  2005     296       1924                3010                3781   \n",
      "14  2004     426       1901                3613                3845   \n",
      "15  2003     379       2370                3795                3929   \n",
      "16  2002     378       2148                3789                4060   \n",
      "17  2001     320       2160                1060                4099   \n",
      "\n",
      "    NorthernRockies  GreatBasin  WesternGreatBasin  Southwest  RockyMountains  \\\n",
      "0              2137        1631                NaN       2072            1394   \n",
      "1              2646        1988                NaN       2172            2150   \n",
      "2              1784        1251                NaN       2084            2048   \n",
      "3              2246         985                NaN       1327            1909   \n",
      "4              1646         782              247.0       1380            1667   \n",
      "5              1468         773              215.0       1519            1455   \n",
      "6              2105        1140              367.0       1410            3592   \n",
      "7              1109         712              383.0       2104            2105   \n",
      "8              1107         810              212.0       1600            1962   \n",
      "9              1344         726              209.0       2074            1434   \n",
      "10             1971         826              224.0       2013            1616   \n",
      "11             2005        1048              425.0       1730            1876   \n",
      "12             2303         943              331.0       2511            2968   \n",
      "13             1183         813              262.0       3287            1940   \n",
      "14             1883         526              173.0       1491             704   \n",
      "15             1970         944              227.0       1657            4214   \n",
      "16             1665         730              215.0       2668            2118   \n",
      "17             1801        2160              277.0       2096            4135   \n",
      "\n",
      "    EasternArea  SouthernArea  Total  \n",
      "0          6822         26754  51576  \n",
      "1          9757         33828  63546  \n",
      "2         11163         33011  60932  \n",
      "3         11553         30067  58916  \n",
      "4          6996         33345  55679  \n",
      "5          7056         14328  38349  \n",
      "6         10942         29549  58331  \n",
      "7          8992         39329  63877  \n",
      "8         15675         36108  64807  \n",
      "9         15719         38103  69650  \n",
      "10        11152         42043  70093  \n",
      "11        12453         43083  73446  \n",
      "12        14227         47175  80220  \n",
      "13        13014         28920  58430  \n",
      "14        11781         27758  54101  \n",
      "15        14851         16479  50815  \n",
      "16        12857         31394  62022  \n",
      "17        18743         34605  70066  \n",
      "Lightning Acres (by Geographic Area\n",
      "[1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "{'Year': ['2018', '2017', '2016', '2015', '2014', '2013', '2012', '2011', '2010', '2009', '2008', '2007', '2006', '2005', '2004', '2003', '2002', '2001'], 'Alaska': ['381,737', '646,133', '486,398', '5,084,752', '10,652', '1,155,109', '253,047', '267,782', '1,018,660', '2,907,710', '60,791', '466,010', '118,974', '4,431,965', '6,506,028', '537,239', '1,749,344', '10,039'], 'Northwest': ['726,518', '655,578', '77,120', '1,121,267', '1,235,931', '388,151', '1,388,293', '273,222', '79,869', '148,328', '183,253', '618,879', '843,984', '122,131', '64,460', '234,331', '988,527', 394], 'NorthernCalifornia': ['92,487', '329,253', '3,007', '285,286', '292,861', '13,517', '592,668', '4,149', '12,973', '49,414', '852,133', '55,394', '174,654', '25,417', '3,689', '45,624', '42,688', '185,212'], 'SouthernCalifornia': ['24,621', '63,233', '14,489', '207,935', '6,136', '32,091', '19,375', '24,402', '16,660', '9,545', '26,140', '43,614', '24,232', '79,450', '8,333', '4,812', '15,661', '135,689'], 'NorthernRockies': ['98,721', '1,416,144', '117,891', '668,042', '114,263', '139,275', '1,218,603', '180,405', '44,900', '36,365', '123,755', '846,734', '1,040,398', '75,450', '14,845', '744,150', '98,402', '137,455'], 'GreatBasin': ['1,057,161', '1,315,019', '428,304', '456,417', '62,187', '737,905', '1,405,873', '398,219', '528,335', '119,995', '25,321', '2,122,801', '966,164', '766,114', '75,551', '172,958', '223,304', '507,190'], 'WesternGreatBasin': ['N/A', 'N/A', 'N/A', 'N/A', '47,107', '152,382', '520,455', '370,152', '20,694', '7,319', '54,161', '844,114', '1,301,924', '988,303', '25,927', '12,418', '48,263', '62,309'], 'Southwest': ['239,689', '363,203', '365,517', '182,890', '156,022', '226,085', '437,039', '467,581', '244,698', '475,436', '234,331', '77,195', '368,626', '571,734', '239,619', '148,384', '345,694', '190,667'], 'RockyMountains': ['244,540', '109,585', '156,090', '16,951', '6,522', '201,863', '850,596', '216,228', '32,929', '30,346', '111,147', '76,502', '449,089', '37,857', '16,921', '93,354', '428,510', '6,453'], 'EasternArea': [374, 246, 948, 200, 286, 357, '26,934', '95,651', '1,454', 427, 420, '19,302', '35,020', '1,834', 309, 125, '1,670', '41,209'], 'SouthernArea': ['216,155', '297,216', '93,621', '88,948', '80,876', '10,831', '113,103', '1,056,805', '118,103', '64,155', '191,025', '708,146', '145,836', '67,982', '55,341', '45,048', '155,530', '545,983'], 'Total': ['3,127,003', '5,195,610', '1,743,385', '8,112,688', '2,012,843', '3,057,566', '6,825,989', '3,354,596', '2,119,275', '3,849,040', '1,862,477', '5,878,691', '5,468,901', '7,168,062', '7,011,023', '2,038,443', '4,097,593', '1,822,600']}\n",
      "    Year   Alaska  Northwest  NorthernCalifornia  SouthernCalifornia  \\\n",
      "0   2018   381737     726518               92487               24621   \n",
      "1   2017   646133     655578              329253               63233   \n",
      "2   2016   486398      77120                3007               14489   \n",
      "3   2015  5084752    1121267              285286              207935   \n",
      "4   2014    10652    1235931              292861                6136   \n",
      "5   2013  1155109     388151               13517               32091   \n",
      "6   2012   253047    1388293              592668               19375   \n",
      "7   2011   267782     273222                4149               24402   \n",
      "8   2010  1018660      79869               12973               16660   \n",
      "9   2009  2907710     148328               49414                9545   \n",
      "10  2008    60791     183253              852133               26140   \n",
      "11  2007   466010     618879               55394               43614   \n",
      "12  2006   118974     843984              174654               24232   \n",
      "13  2005  4431965     122131               25417               79450   \n",
      "14  2004  6506028      64460                3689                8333   \n",
      "15  2003   537239     234331               45624                4812   \n",
      "16  2002  1749344     988527               42688               15661   \n",
      "17  2001    10039        394              185212              135689   \n",
      "\n",
      "    NorthernRockies  GreatBasin  WesternGreatBasin  Southwest  RockyMountains  \\\n",
      "0             98721     1057161                NaN     239689          244540   \n",
      "1           1416144     1315019                NaN     363203          109585   \n",
      "2            117891      428304                NaN     365517          156090   \n",
      "3            668042      456417                NaN     182890           16951   \n",
      "4            114263       62187            47107.0     156022            6522   \n",
      "5            139275      737905           152382.0     226085          201863   \n",
      "6           1218603     1405873           520455.0     437039          850596   \n",
      "7            180405      398219           370152.0     467581          216228   \n",
      "8             44900      528335            20694.0     244698           32929   \n",
      "9             36365      119995             7319.0     475436           30346   \n",
      "10           123755       25321            54161.0     234331          111147   \n",
      "11           846734     2122801           844114.0      77195           76502   \n",
      "12          1040398      966164          1301924.0     368626          449089   \n",
      "13            75450      766114           988303.0     571734           37857   \n",
      "14            14845       75551            25927.0     239619           16921   \n",
      "15           744150      172958            12418.0     148384           93354   \n",
      "16            98402      223304            48263.0     345694          428510   \n",
      "17           137455      507190            62309.0     190667            6453   \n",
      "\n",
      "    EasternArea  SouthernArea    Total  \n",
      "0           374        216155  3127003  \n",
      "1           246        297216  5195610  \n",
      "2           948         93621  1743385  \n",
      "3           200         88948  8112688  \n",
      "4           286         80876  2012843  \n",
      "5           357         10831  3057566  \n",
      "6         26934        113103  6825989  \n",
      "7         95651       1056805  3354596  \n",
      "8          1454        118103  2119275  \n",
      "9           427         64155  3849040  \n",
      "10          420        191025  1862477  \n",
      "11        19302        708146  5878691  \n",
      "12        35020        145836  5468901  \n",
      "13         1834         67982  7168062  \n",
      "14          309         55341  7011023  \n",
      "15          125         45048  2038443  \n",
      "16         1670        155530  4097593  \n",
      "17        41209        545983  1822600  \n",
      "Number Lightning Fires (by Geographic Area\n",
      "[1, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year  Alaska  Northwest  NorthernCalifornia  SouthernCalifornia  \\\n",
      "0   2018     138        977                 174                 131   \n",
      "1   2017     155       1254                 728                 188   \n",
      "2   2016     229        437                  97                  96   \n",
      "3   2015     417       1705                 785                 397   \n",
      "4   2014      55       2417                 477                 259   \n",
      "5   2013     212       2282                 596                 274   \n",
      "6   2012     141        856                 180                 266   \n",
      "7   2011     138        808                 301                 258   \n",
      "8   2010     330       1110                 441                 216   \n",
      "9   2009     199       1843                 890                 179   \n",
      "10  2008      75       1624                1400                 174   \n",
      "11  2007     201       1486                 574                 291   \n",
      "12  2006      54       2170                 948                 409   \n",
      "13  2005     311        901                 186                 272   \n",
      "14  2004     270       2042                 670                 323   \n",
      "15  2003      72       1605                 966                 428   \n",
      "16  2002     165       1797                 301                 179   \n",
      "17  2001      29        159                2238                 832   \n",
      "\n",
      "    NorthernRockies  GreatBasin  WesternGreatBasin  Southwest  RockyMountains  \\\n",
      "0               604        1145                NaN       1216            1086   \n",
      "1              1254        1139                NaN        922            1014   \n",
      "2               916         812                NaN       1413            1247   \n",
      "3              1571        1111                NaN        986             650   \n",
      "4              1019         937              284.0        840             689   \n",
      "5              1305        1441              542.0       1238            1166   \n",
      "6              1328        1259              577.0       1224            1992   \n",
      "7               944        1168              432.0       1678            1328   \n",
      "8               633        1036              273.0        947             941   \n",
      "9              1212        1086              478.0       1546            1090   \n",
      "10              679         835              224.0       1027             941   \n",
      "11             1363        1434              463.0       1869            1672   \n",
      "12             1970        2259              943.0       3220            2479   \n",
      "13              748        1345              536.0       1935            1398   \n",
      "14             1090        1760              781.0       2062            1340   \n",
      "15             1921        2004              569.0       2702            1918   \n",
      "16             1130        1602              556.0       2469            2039   \n",
      "17             1041        2405             1697.0       2298            2114   \n",
      "\n",
      "    EasternArea  SouthernArea  Total  \n",
      "0            69           967   6507  \n",
      "1            59          1240   7953  \n",
      "2           107          1436   6790  \n",
      "3            86          1527   9235  \n",
      "4            34           922   7933  \n",
      "5            54           120   9230  \n",
      "6           205          1415   9443  \n",
      "7           161          3033  10249  \n",
      "8           169          1068   7164  \n",
      "9            62           557   9142  \n",
      "10          171          1706   8856  \n",
      "11          330          2578  12261  \n",
      "12          256          1457  16165  \n",
      "13          175           516   8323  \n",
      "14           88           958  11384  \n",
      "15          102           489  12776  \n",
      "16          372           825  11435  \n",
      "17          889           392  14094  \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SuppCosts.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f802fc1e56ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_lightning_fire_acres\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_lightning_fire_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mget_suppression_costs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mget_total_fires\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-bc097c22ae15>\u001b[0m in \u001b[0;36mget_suppression_costs\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_suppression_costs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Extracts the pdf information as a string object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpdfFileObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SuppCosts.pdf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpdfReader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPdfFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdfFileObj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# print(pdfReader.numPages)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SuppCosts.pdf'"
     ]
    }
   ],
   "source": [
    "get_big_fires()\n",
    "get_human_fire_acres()\n",
    "get_human_fire_num()\n",
    "get_lightning_fire_acres()\n",
    "get_lightning_fire_num()\n",
    "get_suppression_costs()\n",
    "get_total_fires()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Persistence\n",
    "\n",
    "Now that we have downloaded all of the data into csv files, we need to create a database to hold the information so it may be accessed easily. For the purposes of this project I will be setting the database up through a SQL Server that is hosted by Utah State University. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the database --\n",
    "connection_string = f'Driver={{ODBC Driver 13 for SQL Server}};Server=stairway.usu.edu,1433;Database=codycrofoot;Uid={os.environ[\"SQLUserName\"]};Pwd={os.environ[\"SQLPASSWORD\"]}'\n",
    "conn = pyodbc.connect(connection_string, autocommit=True)\n",
    "print(conn)\n",
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Tables\n",
    "\n",
    "I started by pulling the information from the csv and putting it into a list. From there I run a SQL query that runs through the list and puts the information into the appropriate spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_BigFires():\n",
    "    big_fires_col = list()\n",
    "    with open('big_fires.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        i = str(next(reader)).replace('[','').replace(']','').replace(',','').replace(\"'\",\"\")\n",
    "        i = i.split()\n",
    "        print(i, type(i))\n",
    "\n",
    "        big_fires_col = i\n",
    "\n",
    "\n",
    "    curs.execute(\n",
    "        f'''\n",
    "    \n",
    "        CREATE TABLE BigFires(\n",
    "        [generated_id] INT PRIMARY KEY CLUSTERED IDENTITY(1,1)\n",
    "        ,{big_fires_col[0]} int\n",
    "        ,{big_fires_col[1]} varchar(60)\n",
    "        ,{big_fires_col[2]} varchar(2)\n",
    "        ,{big_fires_col[3]} float\n",
    "        ,\n",
    "        )\n",
    "    \n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TotalFires():\n",
    "    total_fires_col = list()\n",
    "    with open('total_fires.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        i = str(next(reader)).replace('[','').replace(']','').replace(',','').replace(\"'\",\"\")\n",
    "        i = i.split()\n",
    "        print(i, type(i))\n",
    "\n",
    "        total_fires_col = i\n",
    "    # print(total_fires_col, type(total_fires_col))\n",
    "\n",
    "    curs.execute(\n",
    "        f'''\n",
    "    \n",
    "        CREATE TABLE TotalFires(\n",
    "        [generated_id] INT PRIMARY KEY CLUSTERED IDENTITY(1,1)\n",
    "        ,{total_fires_col[0]} int\n",
    "        ,{total_fires_col[1]} float\n",
    "        ,{total_fires_col[2]} float\n",
    "        ,\n",
    "        )\n",
    "    \n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_HumanFireAcres():\n",
    "    human_fire_acres_col = list()\n",
    "    with open('human_fire_acres.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        i = str(next(reader)).replace('[','').replace(']','').replace(',','').replace(\"'\",\"\")\n",
    "        i = i.split()\n",
    "\n",
    "        human_fire_acres_col = i\n",
    "\n",
    "    # print(human_fire_acres_col)\n",
    "\n",
    "    curs.execute(\n",
    "        f'''\n",
    "    \n",
    "        CREATE TABLE HumanFireAcres(\n",
    "        [generated_id] INT PRIMARY KEY CLUSTERED IDENTITY(1,1)\n",
    "        ,{human_fire_acres_col[0]} int\n",
    "        ,{human_fire_acres_col[1]} float\n",
    "        ,{human_fire_acres_col[2]} float\n",
    "        ,{human_fire_acres_col[3]} float\n",
    "        ,{human_fire_acres_col[4]} float\n",
    "        ,{human_fire_acres_col[5]} float\n",
    "        ,{human_fire_acres_col[6]} float\n",
    "        ,{human_fire_acres_col[7]} float\n",
    "        ,{human_fire_acres_col[8]} float\n",
    "        ,{human_fire_acres_col[9]} float\n",
    "        ,{human_fire_acres_col[10]} float\n",
    "        ,{human_fire_acres_col[11]} float\n",
    "        ,{human_fire_acres_col[12]} float\n",
    "        )\n",
    "    ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_HumanFireNum():\n",
    "    human_fire_num_col = list()\n",
    "    with open('human_fire_num.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        i = str(next(reader)).replace('[','').replace(']','').replace(',','').replace(\"'\",\"\")\n",
    "        i = i.split()\n",
    "\n",
    "        human_fire_num_col = i\n",
    "\n",
    "    # print(human_fire_num_col)\n",
    "\n",
    "    curs.execute(\n",
    "        f'''\n",
    "    \n",
    "        CREATE TABLE HumanFireNum(\n",
    "        [generated_id] INT PRIMARY KEY CLUSTERED IDENTITY(1,1)\n",
    "        ,{human_fire_num_col[0]} int\n",
    "        ,{human_fire_num_col[1]} float\n",
    "        ,{human_fire_num_col[2]} float\n",
    "        ,{human_fire_num_col[3]} float\n",
    "        ,{human_fire_num_col[4]} float\n",
    "        ,{human_fire_num_col[5]} float\n",
    "        ,{human_fire_num_col[6]} float\n",
    "        ,{human_fire_num_col[7]} float\n",
    "        ,{human_fire_num_col[8]} float\n",
    "        ,{human_fire_num_col[9]} float\n",
    "        ,{human_fire_num_col[10]} float\n",
    "        ,{human_fire_num_col[11]} float\n",
    "        ,{human_fire_num_col[12]} float\n",
    "        )\n",
    "    ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LightningFireAcres():\n",
    "    lightning_fire_acres_col = list()\n",
    "    with open('lightning_fire_acres.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        i = str(next(reader)).replace('[','').replace(']','').replace(',','').replace(\"'\",\"\")\n",
    "        i = i.split()\n",
    "\n",
    "        lightning_fire_acres_col = i\n",
    "\n",
    "    # print(lightning_fire_acres_col)\n",
    "\n",
    "    curs.execute(\n",
    "        f'''\n",
    "    \n",
    "        CREATE TABLE LightningFireAcres(\n",
    "        [generated_id] INT PRIMARY KEY CLUSTERED IDENTITY(1,1)\n",
    "        ,{lightning_fire_acres_col[0]} int\n",
    "        ,{lightning_fire_acres_col[1]} float\n",
    "        ,{lightning_fire_acres_col[2]} float\n",
    "        ,{lightning_fire_acres_col[3]} float\n",
    "        ,{lightning_fire_acres_col[4]} float\n",
    "        ,{lightning_fire_acres_col[5]} float\n",
    "        ,{lightning_fire_acres_col[6]} float\n",
    "        ,{lightning_fire_acres_col[7]} float\n",
    "        ,{lightning_fire_acres_col[8]} float\n",
    "        ,{lightning_fire_acres_col[9]} float\n",
    "        ,{lightning_fire_acres_col[10]} float\n",
    "        ,{lightning_fire_acres_col[11]} float\n",
    "        ,{lightning_fire_acres_col[12]} float\n",
    "        )\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LightningFireNum():\n",
    "    lightning_fire_num_col = list()\n",
    "    with open('lightning_fire_num.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        i = str(next(reader)).replace('[','').replace(']','').replace(',','').replace(\"'\",\"\")\n",
    "        i = i.split()\n",
    "\n",
    "        lightning_fire_num_col = i\n",
    "\n",
    "    # print(lightning_fire_num_col)\n",
    "\n",
    "    curs.execute(\n",
    "        f'''\n",
    "    \n",
    "        CREATE TABLE LightningFireNum(\n",
    "        [generated_id] INT PRIMARY KEY CLUSTERED IDENTITY(1,1)\n",
    "        ,{lightning_fire_num_col[0]} int\n",
    "        ,{lightning_fire_num_col[1]} float\n",
    "        ,{lightning_fire_num_col[2]} float\n",
    "        ,{lightning_fire_num_col[3]} float\n",
    "        ,{lightning_fire_num_col[4]} float\n",
    "        ,{lightning_fire_num_col[5]} float\n",
    "        ,{lightning_fire_num_col[6]} float\n",
    "        ,{lightning_fire_num_col[7]} float\n",
    "        ,{lightning_fire_num_col[8]} float\n",
    "        ,{lightning_fire_num_col[9]} float\n",
    "        ,{lightning_fire_num_col[10]} float\n",
    "        ,{lightning_fire_num_col[11]} float\n",
    "        ,{lightning_fire_num_col[12]} float\n",
    "        )\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_SuppressionCosts():\n",
    "    suppression_costs_col = list()\n",
    "    with open('suppression_costs.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        i = str(next(reader)).replace('[','').replace(']','').replace(',','').replace(\"'\",\"\")\n",
    "        i = i.split()\n",
    "\n",
    "        suppression_costs_col = i\n",
    "\n",
    "    # print(suppression_costs_col)\n",
    "\n",
    "    curs.execute(\n",
    "        f'''\n",
    "    \n",
    "        CREATE TABLE SuppressionCosts(\n",
    "        [generated_id] INT PRIMARY KEY CLUSTERED IDENTITY(1,1)\n",
    "        ,{suppression_costs_col[0]} int\n",
    "        ,{suppression_costs_col[1]} float\n",
    "        ,{suppression_costs_col[2]} float\n",
    "        ,{suppression_costs_col[3]} float\n",
    "        ,{suppression_costs_col[4]} float\n",
    "        ,{suppression_costs_col[5]} float\n",
    "        )\n",
    "    ''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_big_fires():\n",
    "    with open ('big_fires.csv', 'r') as f:\n",
    "        reader = csv.reader(f, )\n",
    "        columns = next(reader)\n",
    "        print(\"\\n\\n\\n-----------Populating BigFires-------------\\n\")\n",
    "\n",
    "        for data in reader:\n",
    "            query = 'insert into BigFires({0})'\n",
    "\n",
    "            query = query.format(','.join(columns), ','.join('?' * (len(columns) - 1)))\n",
    "\n",
    "            col = str(data[0])\n",
    "            for i in range(len(data)-1):\n",
    "                if type(data[i+1]) == type('string'):\n",
    "                    col = col + \",'\" + str(data[i + 1]) + \"'\"\n",
    "                else:\n",
    "                    col = col + \",\" + str(data[i+1])\n",
    "            query = query + f' values ({col});'\n",
    "            print(query)\n",
    "\n",
    "            curs.execute(query)\n",
    "        curs.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_total_fires():\n",
    "    with open ('total_fires.csv', 'r') as f:\n",
    "        reader = csv.reader(f, )\n",
    "        columns = next(reader)\n",
    "        print(\"\\n\\n\\n-----------Populating TotalFires-------------\\n\")\n",
    "\n",
    "        for data in reader:\n",
    "            query = 'insert into TotalFires({0})'\n",
    "\n",
    "            query = query.format(','.join(columns), ','.join('?' * (len(columns) - 1)))\n",
    "\n",
    "            col = str(data[0])\n",
    "            for i in range(len(data)-1):\n",
    "                if type(data[i+1]) == type('string'):\n",
    "                    col = col + \",'\" + str(data[i + 1]) + \"'\"\n",
    "                else:\n",
    "                    col = col + \",\" + str(data[i+1])\n",
    "            query = query + f' values ({col});'\n",
    "            print(query)\n",
    "\n",
    "            curs.execute(query)\n",
    "        curs.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_human_fire_acres():\n",
    "    with open ('human_fire_acres.csv', 'r') as f:\n",
    "        reader = csv.reader(f, )\n",
    "        columns = next(reader)\n",
    "        print(\"\\n\\n\\n-----------Populating HumanFireAcres-------------\\n\")\n",
    "\n",
    "\n",
    "        for data in reader:\n",
    "            query = 'insert into HumanFireAcres({0})'\n",
    "\n",
    "            query = query.format(','.join(columns), ','.join('?' * (len(columns) - 1)))\n",
    "\n",
    "            col = str(data[0])\n",
    "            for i in range(len(data)-1):\n",
    "                if type(data[i+1]) == type('string'):\n",
    "                    col = col + \",'\" + str(data[i + 1]) + \"'\"\n",
    "                else:\n",
    "                    col = col + \",\" + str(data[i+1])\n",
    "            query = query + f' values ({col});'\n",
    "            print(query)\n",
    "\n",
    "            curs.execute(query)\n",
    "        curs.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_human_fire_num():\n",
    "    with open ('human_fire_num.csv', 'r') as f:\n",
    "        reader = csv.reader(f, )\n",
    "        columns = next(reader)\n",
    "        print(\"\\n\\n\\n-----------Populating HumanFireNum-------------\\n\")\n",
    "\n",
    "\n",
    "        for data in reader:\n",
    "            query = 'insert into HumanFireNum({0})'\n",
    "\n",
    "            query = query.format(','.join(columns), ','.join('?' * (len(columns) - 1)))\n",
    "\n",
    "            col = str(data[0])\n",
    "            for i in range(len(data)-1):\n",
    "                if type(data[i+1]) == type('string'):\n",
    "                    col = col + \",'\" + str(data[i + 1]) + \"'\"\n",
    "                else:\n",
    "                    col = col + \",\" + str(data[i+1])\n",
    "            query = query + f' values ({col});'\n",
    "            print(query)\n",
    "\n",
    "            curs.execute(query)\n",
    "        curs.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_lightning_fire_acres():\n",
    "    with open ('lightning_fire_acres.csv', 'r') as f:\n",
    "        reader = csv.reader(f, )\n",
    "        columns = next(reader)\n",
    "        print(\"\\n\\n\\n-----------Populating LightningFireAcres-------------\\n\")\n",
    "\n",
    "\n",
    "        for data in reader:\n",
    "            query = 'insert into LightningFireAcres({0})'\n",
    "\n",
    "            query = query.format(','.join(columns), ','.join('?' * (len(columns) - 1)))\n",
    "\n",
    "            col = str(data[0])\n",
    "            for i in range(len(data)-1):\n",
    "                if type(data[i+1]) == type('string'):\n",
    "                    col = col + \",'\" + str(data[i + 1]) + \"'\"\n",
    "                else:\n",
    "                    col = col + \",\" + str(data[i+1])\n",
    "            query = query + f' values ({col});'\n",
    "            print(query)\n",
    "\n",
    "            curs.execute(query)\n",
    "        curs.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_lightning_fire_num():\n",
    "    with open ('lightning_fire_num.csv', 'r') as f:\n",
    "        reader = csv.reader(f, )\n",
    "        columns = next(reader)\n",
    "        print(\"\\n\\n\\n-----------Populating LightningFireNum-------------\\n\")\n",
    "\n",
    "\n",
    "        for data in reader:\n",
    "            query = 'insert into LightningFireNum({0})'\n",
    "\n",
    "            query = query.format(','.join(columns), ','.join('?' * (len(columns) - 1)))\n",
    "\n",
    "            col = str(data[0])\n",
    "            for i in range(len(data)-1):\n",
    "                if type(data[i+1]) == type('string'):\n",
    "                    col = col + \",'\" + str(data[i + 1]) + \"'\"\n",
    "                else:\n",
    "                    col = col + \",\" + str(data[i+1])\n",
    "            query = query + f' values ({col});'\n",
    "            print(query)\n",
    "\n",
    "            curs.execute(query)\n",
    "        curs.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_suppression_costs():\n",
    "    with open ('suppression_costs.csv', 'r') as f:\n",
    "        reader = csv.reader(f, )\n",
    "        columns = next(reader)\n",
    "        print(\"\\n\\n\\n-----------Populating SuppressionCosts-------------\\n\")\n",
    "\n",
    "\n",
    "        for data in reader:\n",
    "            query = 'insert into SuppressionCosts({0})'\n",
    "\n",
    "            query = query.format(','.join(columns), ','.join('?' * (len(columns) - 1)))\n",
    "\n",
    "            col = str(data[0])\n",
    "            for i in range(len(data)-1):\n",
    "                if type(data[i+1]) == type('string'):\n",
    "                    col = col + \",'\" + str(data[i + 1]) + \"'\"\n",
    "                else:\n",
    "                    col = col + \",\" + str(data[i+1])\n",
    "            query = query + f' values ({col});'\n",
    "            print(query)\n",
    "\n",
    "            curs.execute(query)\n",
    "        curs.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database frame\n",
    "create_BigFires()\n",
    "create_TotalFires()\n",
    "create_HumanFireAcres()\n",
    "create_HumanFireNum()\n",
    "create_LightningFireAcres()\n",
    "create_LightningFireNum()\n",
    "create_SuppressionCosts()\n",
    "\n",
    "# Populates the database\n",
    "populate_big_fires()\n",
    "populate_total_fires()\n",
    "populate_human_fire_acres()\n",
    "populate_human_fire_num()\n",
    "populate_lightning_fire_acres()\n",
    "populate_lightning_fire_num()\n",
    "populate_suppression_costs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with API\n",
    "For the API, I wanted to keep things simple. There are basic commands to access data from each table as add and delete as well. Currently the add function only adds a test row to prove that it is functional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from flask import Flask, g, abort\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Globals\n",
    "CONNECTION_STRING = f'Driver={{ODBC Driver 13 for SQL Server}};Server=stairway.usu.edu,1433;Database=codycrofoot;Uid={os.environ[\"SQLUserName\"]};Pwd={os.environ[\"SQLPASSWORD\"]}'\n",
    "\n",
    "\n",
    "# Setup Flask\n",
    "app = Flask(__name__)\n",
    "app.config.from_object(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before / Teardown\n",
    "@app.before_request\n",
    "def before_request():\n",
    "    try:\n",
    "        g.conn =  pyodbc.connect(CONNECTION_STRING, autocommit=True)\n",
    "    except Exception:\n",
    "        abort(500, \"No database connection could be established.\")\n",
    "\n",
    "@app.teardown_request\n",
    "def teardown_request(exception):\n",
    "    try:\n",
    "        g.conn.close()\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Default Route\n",
    "@app.route('/', methods=['GET'])\n",
    "def hello():\n",
    "    return '''Welcome to the wildfire Database. \n",
    "            From this website you have access to all major wildfires\n",
    "            greater than 100,000 acres. The information comes from a\n",
    "            government website. You have the following options: \n",
    "            --(1)Go to (\"/wildfires\") to see all of the data\\n\n",
    "            --(2)Go to (\"/wildfire/<id>\") to see a single returned item \\n\n",
    "            --(3)Go to (\"/wildfire/post\") and do a POST to add test data to the database\n",
    "            --(4)Go to (\"/wildfire/delete/<id>\" and do a DELETE to delete data of your choice\n",
    "            \n",
    "            Thanks for visiting!!!\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sections will set up the specifics for each fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Big Fires #\n",
    "#############\n",
    "\n",
    "# GET All BigFires Data\n",
    "@app.route('/bigfires', methods=['GET'])\n",
    "def get_bigfires_data():\n",
    "\n",
    "    curs = g.conn.cursor()\n",
    "    query = 'select * from BigFires'\n",
    "    curs.execute(query)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n",
    "\n",
    "# GET Single Wildfire\n",
    "@app.route('/bigfires/<string:id>', methods=['GET'])\n",
    "def get_single_bigfires_data(id):\n",
    "    curs = g.conn.cursor()\n",
    "    curs.execute(\"select * from BigFires where generated_id = ?\", id)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# FIRE CAUSES - LightningFireNum #\n",
    "##################################\n",
    "\n",
    "# GET All LightningFireNum Data\n",
    "@app.route('/lightningFireNum', methods=['GET'])\n",
    "def get_lightningFireNum_data():\n",
    "\n",
    "    curs = g.conn.cursor()\n",
    "    query = 'select * from LightningFireNum'\n",
    "    curs.execute(query)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n",
    "\n",
    "# GET Single Wildfire\n",
    "@app.route('/lightningFireNum/<string:id>', methods=['GET'])\n",
    "def get_single_lightningFireNum_data(id):\n",
    "    curs = g.conn.cursor()\n",
    "    curs.execute(\"select * from lightningFireNum where generated_id = ?\", id)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# FIRE CAUSES - LightningFireAcres #\n",
    "####################################\n",
    "\n",
    "# GET All LightningFireNum Data\n",
    "@app.route('/lightningFireAcres', methods=['GET'])\n",
    "def get_lightningFireAcres_data():\n",
    "\n",
    "    curs = g.conn.cursor()\n",
    "    query = 'select * from LightningFireAcres'\n",
    "    curs.execute(query)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n",
    "\n",
    "# GET Single Wildfire\n",
    "@app.route('/lightningFireAcres/<string:id>', methods=['GET'])\n",
    "def get_single_lightningFireAcres_data(id):\n",
    "    curs = g.conn.cursor()\n",
    "    curs.execute(\"select * from lightningFireAcres where generated_id = ?\", id)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# FIRE CAUSES - HumanFireNum #\n",
    "##############################\n",
    "\n",
    "# GET All LightningFireNum Data\n",
    "@app.route('/HumanFireNum', methods=['GET'])\n",
    "def get_HumanFireNum_data():\n",
    "\n",
    "    curs = g.conn.cursor()\n",
    "    query = 'select * from HumanFireNum'\n",
    "    curs.execute(query)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n",
    "\n",
    "# GET Single Wildfire\n",
    "@app.route('/HumanFireNum/<string:id>', methods=['GET'])\n",
    "def get_single_HumanFireNum_data(id):\n",
    "    curs = g.conn.cursor()\n",
    "    curs.execute(\"select * from HumanFireNum where generated_id = ?\", id)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# FIRE CAUSES - HumanFireAcres #\n",
    "################################\n",
    "\n",
    "# GET All LightningFireNum Data\n",
    "@app.route('/HumanFireAcres', methods=['GET'])\n",
    "def get_HumanFireAcres_data():\n",
    "\n",
    "    curs = g.conn.cursor()\n",
    "    query = 'select * from HumanFireAcres'\n",
    "    curs.execute(query)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n",
    "\n",
    "# GET Single Wildfire\n",
    "@app.route('/HumanFireAcres/<string:id>', methods=['GET'])\n",
    "def get_single_HumanFireAcres_data(id):\n",
    "    curs = g.conn.cursor()\n",
    "    curs.execute(\"select * from HumanFireAcres where generated_id = ?\", id)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# TOTAL FIRES #\n",
    "###############\n",
    "\n",
    "# GET All TotalFires Data\n",
    "@app.route('/TotalFires', methods=['GET'])\n",
    "def get_TotalFires_data():\n",
    "\n",
    "    curs = g.conn.cursor()\n",
    "    query = 'select * from TotalFires'\n",
    "    curs.execute(query)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n",
    "\n",
    "# GET Single Wildfire\n",
    "@app.route('/TotalFires/<string:id>', methods=['GET'])\n",
    "def get_single_TotalFires_data(id):\n",
    "    curs = g.conn.cursor()\n",
    "    curs.execute(\"select * from TotalFires where generated_id = ?\", id)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# SUPPRESSION COSTS #\n",
    "#####################\n",
    "\n",
    "# GET All SuppressionCosts Data\n",
    "@app.route('/suppressioncosts', methods=['GET'])\n",
    "def get_suppression_costs_data():\n",
    "\n",
    "    curs = g.conn.cursor()\n",
    "    query = 'select * from SuppressionCosts'\n",
    "    curs.execute(query)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)\n",
    "\n",
    "# GET Single Wildfire\n",
    "@app.route('/SuppressionCosts/<string:id>', methods=['GET'])\n",
    "def get_single_suppression_costs_data(id):\n",
    "    curs = g.conn.cursor()\n",
    "    curs.execute(\"select * from SuppressionCosts where generated_id = ?\", id)\n",
    "\n",
    "    columns = [column[0] for column in curs.description]\n",
    "    data = []\n",
    "\n",
    "    for row in curs.fetchall():\n",
    "        data.append(dict(zip(columns, row)))\n",
    "\n",
    "    return json.dumps(data, indent=4, sort_keys=True, default=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the code for posting and deleting. They are only functional on the BigFires table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST API (Add)\n",
    "@app.route('/wildfire/post', methods=['POST'])\n",
    "def insertnew():\n",
    "    curs = g.conn.cursor()\n",
    "\n",
    "    curs.execute(\"insert into BigFires (Year,FireName,State,TotalAcres) VALUES (2020,'TESTPOSTFIRE','ID',12)\")\n",
    "    curs.commit()\n",
    "\n",
    "    return 'success', 200\n",
    "\n",
    "\n",
    "# DELETE API (Add)\n",
    "@app.route('/wildfire/delete/<string:id>', methods=['DELETE'])\n",
    "def deletetest(id):\n",
    "    curs = g.conn.cursor()\n",
    "\n",
    "    curs.execute(\"DELETE FROM BigFires WHERE generated_id=?\", id)\n",
    "    curs.commit()\n",
    "\n",
    "    return 'success', 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
